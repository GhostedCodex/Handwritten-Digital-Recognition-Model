{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f9fd97",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069dfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8863e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Original shape: (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizing the images to the range [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "print(f\"Original shape: {X_train.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162b111",
   "metadata": {},
   "source": [
    "Building the Architecture (The \"Stack\")\n",
    "Input Layer (Flatten): Converts the 2D image ($28 \\times 28$) into a 1D line ($784$ numbers).\n",
    "Hidden Layer (Dense): The \"brain\" that learns patterns.Using 128 neurons.\n",
    "Output Layer (Dense): The decision maker. It has 10 neurons (one for each digit 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6cb1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HUMAIDU\\anaconda3\\envs\\mlpython310\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Layer 1: Flatten the 28x28 images to a 1D vector of 784 pixels\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    # Layer 2: Dense (Fully Connected) layer with 128 neurons\n",
    "    # Activation='relu' makes the network non-linear (it decides if a neuron \"fires\")\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # Layer 3: Output layer with 10 neurons (one for each digit)\n",
    "    # Activation='softmax' turns the output into probabilities (they sum to 1)\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ec565",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63df29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d9cfa",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "794d1c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9245 - loss: 0.2643\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.1166\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0797\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0612\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0468\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e5e9c3",
   "metadata": {},
   "source": [
    "## Evaluation and Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "981f8128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - 1ms/step - accuracy: 0.9767 - loss: 0.0729\n",
      "\n",
      "Test accuracy: 0.9767000079154968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on test data \n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# Make predictions on the first image on the test set\n",
    "predictions = model.predict(X_test[:1]) # to pass the first image only\n",
    "\n",
    "# To visualize \n",
    "plt.imshow(X_test[0], cmap=\"gray\")\n",
    "plt.title(f\"Predicted Label: {np.argmax(predictions[0])}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d0deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpython310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
